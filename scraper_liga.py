import pandas as pd
import requests
from io import StringIO 

url = "https://es.wikipedia.org/wiki/Categor%C3%ADa_Primera_A"
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

print("üì° Conectando con Wikipedia...")

try:
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    
    # Leemos el HTML
    tablas = pd.read_html(StringIO(response.text))
    
    # Buscamos la tabla de campeones
    tabla_campeones = None
    for tabla in tablas:
        # Convertimos columnas a texto para buscar palabras clave
        cols_str = str(tabla.columns).lower()
        if "campe√≥n" in cols_str and "subcampe√≥n" in cols_str:
            tabla_campeones = tabla.copy() # Hacemos una copia para no da√±ar el original
            break
            
    if tabla_campeones is not None:
        print("‚úÖ Tabla encontrada. Procesando encabezados...")

        # --- NUEVO: APLANAR ENCABEZADOS (El truco m√°gico) ---
        # Si la tabla tiene encabezados m√∫ltiples (MultiIndex), los unimos con un espacio
        if isinstance(tabla_campeones.columns, pd.MultiIndex):
            nuevas_columnas = []
            for col in tabla_campeones.columns.values:
                # Une los niveles del encabezado (Ej: "A√±o" + "Nivel1" -> "A√±o")
                nombre_col = ' '.join(map(str, col)).strip()
                nuevas_columnas.append(nombre_col)
            tabla_campeones.columns = nuevas_columnas

        print(f"Primera fila hist√≥rica: {tabla_campeones.iloc[0, 0]}") # Deber√≠a decir 1948

        # Guardamos
        archivo = "historial_fpc.xlsx"
        tabla_campeones.to_excel(archivo, index=False)
        print(f"\nüíæ ¬°GOLAZO! Archivo guardado: {archivo}")
        
    else:
        print("‚ö†Ô∏è No encontr√© la tabla exacta.")

except Exception as e:
    print(f"‚ùå Error: {e}")